{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tutorial 1: Land-cover classification\n",
    "\n",
    "In this tutorial we are going to explore the power of the **Google Earth Engine** through classifying land-use categories on satelite imagery. In particular, we will focus on supervised classification. Supervised classification refers to the process of using a training dataset with known labels to guide a mathematical classifier in the task of labeling spectral space. They key characteristic is that the training dataset guides (or “supervises”) the labeling.\n",
    "\n",
    "Although the specifics of the steps vary by classifier, the supervised classification workflow in **Google Earth Engine** is similar across most variants.\n",
    "\n",
    "- Get an image.\n",
    "- Get training data.\n",
    "- Train a classifier or clusterer.\n",
    "- Apply that classifier to the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- To understand how one can extract data from the **Google Earth Engine**.\n",
    "- To know how to visualize data from the **Google Earth Engine** in Python.\n",
    "- To understand and apply a supervised classification algorithm.\n",
    "- To be able to create training data and a simple classifier.\n",
    "- To classify Landsat-8 data using various training datasets.\n",
    "- To be able to compare and judge the performance of a land-use classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Tutorial Outline<span class=\"tocSkip\"></span></h2>\n",
    "<hr>\n",
    "<div class=\"toc\"><ul class=\"toc-item\">\n",
    "<li><span><a href=\"#1.-Introducing the packages\" data-toc-modified-id=\"1.-Introducing-the-packages-2\">1. Introducing the packages</a></span></li>\n",
    "<li><span><a href=\"#2.-Extracting and exploring Landsat-8 data\" data-toc-modified-id=\"2.-Extracting-exploring-landsat-3\">2. Extracting and exploring Landsat-8 data</a></span></li>\n",
    "<li><span><a href=\"#3.-Create training data using Corine Land Cover\" data-toc-modified-id=\"3.-Create-training-data-4\">3. Create training data using Corine Land Cover</a></span></li>\n",
    "<li><span><a href=\"#4.-Train the classifier using Corine Land Cover\" data-toc-modified-id=\"4.-Classifier-CLC-5\">4.-Train the classifier using Corine Land Cover</a></span></li>\n",
    "<li><span><a href=\"#5.-Classify the Landsat-8 using Corine Land Cover\" data-toc-modified-id=\"5.-Classify-CLC-6\"> 5. Classify the Landsat-8 using Corine Land Cover</a></span></li>\n",
    "<li><span><a href=\"#6.-Classify the Landsat-8 using ESA WorldCover\" data-toc-modified-id=\"6.-Classify-ESA-7\"> 6. Classify the Landsat-8 using ESA WorldCover</a></span></li>\n",
    "<li><span><a href=\"#7.-Analyze and assess your Landsat-8 land cover map\" data-toc-modified-id=\"6.-Analyze-LLC-7\"> 7. Analyze and assess your Landsat-8 land cover map</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Introducing the packages\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within this tutorial, we are going to make use of the following packages: \n",
    "\n",
    "[**ee**](https://developers.google.com/earth-engine/guides/python_install) is a Python package to use the the Google Earth Engine.\n",
    "\n",
    "[**geemap**](https://geemap.org/) is a Python package for interactive mapping with the Google Earth Engine.\n",
    "\n",
    "*We will first need to install these packages in the cell below. Uncomment them to make sure we can pip install them*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ee\n",
    "#!pip install geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Extracting and exploring the Landsat-8 data\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately it is not as simple as just running the  code below. As soon as you run it, you will notice that you need to authorize ourselves to be able to use the Google Earth Engine.\n",
    "\n",
    "To do so, we will first have to register ourselves. on the website of the [Google Earth Engine](https://earthengine.google.com/). In the video below we will show you how to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8bafbc93ce2401f819735d458b1fcc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[52.37, 4.5], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map = geemap.Map(height=800,width=700,center=[52.37,4.5],zoom=7)\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have succesfully managed to see a map of the Netherlands, let's add Landsat data to the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "point = ee.Geometry.Point([5.0, 51.37])\n",
    "# point = ee.Geometry.Point([-87.7719, 41.8799])\n",
    "\n",
    "image = (\n",
    "    ee.ImageCollection('LANDSAT/LC08/C01/T1_SR')\n",
    "    .filterBounds(point)\n",
    "    .filterDate('2020-01-01', '2020-12-31')\n",
    "    .sort('CLOUD_COVER')\n",
    "    .first()\n",
    "    .select('B[1-7]')\n",
    ")\n",
    "\n",
    "vis_params = {'min': 0, 'max': 3000, 'bands': ['B4', 'B3', 'B2']}\n",
    "\n",
    "Map.centerObject(point, 8)\n",
    "Map.addLayer(image, vis_params, \"Landsat-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It worked! As we have specified that we wanted landsat data with as little clouds as possible, let's check the data and the actual cloud cover:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020-07-31'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ee.Date(image.get('system:time_start')).format('YYYY-MM-dd').getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.get('CLOUD_COVER').getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Create training data using Corine Land Cover\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data is instrumental to supervised image classification. The training dataset is a labeled set of data that is used to inform or “train” a classifier. The trained classifier can then be applied to new data to create a classification. For example, land cover training data will contain examples of each class in the study’s legend. Based on these labels, the classifier can predict the most likely land cover class for each pixel in an image. This is an example of a categorical classification and the training labels are therefore categorical. By contrast, a continuous variable (e.g. percent tree cover) can be predicted using continuous training labels.\n",
    "\n",
    "Let us first specify the region we are interested in! There are several ways you can create a region for generating the training dataset.\n",
    "\n",
    "- Draw a shape (e.g., rectangle) on the map and the use `region = Map.user_roi`\n",
    "- Define a geometry, such as `region = ee.Geometry.Rectangle([-122.6003, 37.4831, -121.8036, 37.8288])`\n",
    "- Create a buffer zone around a point, such as `region = ee.Geometry.Point([-122.4439, 37.7538]).buffer(10000)`\n",
    "- If you don't define a region, it will use the image footprint by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = ee.Geometry.Point([4.5, 52.37]).buffer(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's explore the Corine Land Cover data.\n",
    "\n",
    "As you will see in the cell below, we use the path where the data is located within the **Google Earth Engine** and specify that we want to see the landcover. \n",
    "\n",
    "Within that same line, we also use the `.clip()` function in which we define that we specifically only want to see the same area as the Landsat-8 image we already selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLC = ee.Image('COPERNICUS/CORINE/V20/100m/2012').select('landcover').clip(image.geometry())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's view it on a map again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8bafbc93ce2401f819735d458b1fcc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=22033.0, center=[51.37, 4.999999999999999], controls=(WidgetControl(options=['position', 'transpare…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map.addLayer(CLC, {}, 'CLC')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to make the training dataset.\n",
    "\n",
    "In the `sample()` function, we have to specify multiple arguments:\n",
    "\n",
    "- Through the `region`argument we specify the geographic boundary of our training dataset.\n",
    "- Through the `scale` argument we specify the size of the points for our sample (30 would indicate 30m).\n",
    "- Through the `numPixels` argument we specify how many pixels we want to extract.\n",
    "- Through the `seed` argument we specify which random selection order we want. Through using a seed, you can always reproduce your results.\n",
    "- Through the `geometries` argument we specify whether we want to extract the geometries as well. This should always be set to True.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = CLC.sample(\n",
    "    **{\n",
    "        'region': image.geometry(),\n",
    "        'scale': 100,\n",
    "        'numPixels': 5000,\n",
    "        'seed': 1,\n",
    "        'geometries': True,  # Set this to False to ignore geometries\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how many points we got for our sample set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4961\n"
     ]
    }
   ],
   "source": [
    "print(points.size().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And what is the information within each of the points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Feature', 'geometry': {'type': 'Point', 'coordinates': [4.626244711173917, 50.89856956194049]}, 'id': '0', 'properties': {'landcover': 112}}\n"
     ]
    }
   ],
   "source": [
    "print(points.first().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.-Train the classifier using Corine Land Cover\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created the points, we need to sample the Landsat-8 imagery using `.sampleRegions()`. This function will extract the reflectance in the designated bands for each of the points you have created. \n",
    "\n",
    "We will use reflectance from the optical, NIR, and SWIR bands (B2 - B7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these bands for prediction.\n",
    "bands = ['B1', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7']\n",
    "\n",
    "# This property of the table stores the land cover labels.\n",
    "label = 'landcover'\n",
    "\n",
    "# Overlay the points on the imagery to get training.\n",
    "training = image.select(bands).sampleRegions(\n",
    "    **{'collection': points, 'properties': [label], 'scale': 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very important part of training a machine learning algorithm is that you ensure that there is some part of your training data left to validate your results. Here we split approximately  80% of the features into a training set and 20% into a validation set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = points.randomColumn();\n",
    "trainingSample = sample.filter('random <= 0.8');\n",
    "validationSample = sample.filter('random > 0.8');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we extract the pixels from the LandSat-8 imagery a well to finalize our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay the points on the imagery to get training.\n",
    "training = image.select(bands).sampleRegions(\n",
    "    **{'collection': trainingSample, 'properties': [label], 'scale': 10}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Classify and visualise the Landsat-8 using Corine Land Cover\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use a CART classifier to find the best method to use the spectral values to separate the labels. The classifiers known as Classification and Regression Trees (CART) partition the spectral data space successive binary splits arranged in a tree form.\n",
    "\n",
    "Graphically, classification trees identify lines that successively split the data space to separate the training points into their classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = ee.Classifier.smileCart().train(training, label, bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a confusion matrix and overall accuracy for the training sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>:root {\n",
       "  --font-color-primary: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --font-color-secondary: var(--jp-content-font-color2, rgba(0, 0, 0, 0.6));\n",
       "  --font-color-accent: rgba(123, 31, 162, 1);\n",
       "  --border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --background-color: var(--jp-layout-color0, white);\n",
       "  --background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=\"dark\"],\n",
       "body[data-theme=\"dark\"],\n",
       "body.vscode-dark {\n",
       "  --font-color-primary: rgba(255, 255, 255, 1);\n",
       "  --font-color-secondary: rgba(255, 255, 255, 0.6);\n",
       "  --font-color-accent: rgb(173, 132, 190);\n",
       "  --border-color: #2e2e2e;\n",
       "  --background-color: #111111;\n",
       "  --background-color-row-even: #111111;\n",
       "  --background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".ee {\n",
       "  padding: 1em;\n",
       "  line-height: 1.5em;\n",
       "  min-width: 300px;\n",
       "  max-width: 1200px;\n",
       "  overflow-y: scroll;\n",
       "  max-height: 600px;\n",
       "  border: 1px solid var(--border-color);\n",
       "  font-family: monospace;\n",
       "}\n",
       "\n",
       ".ee li {\n",
       "  list-style-type: none;\n",
       "}\n",
       "\n",
       ".ee ul {\n",
       "  padding-left: 1.5em !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".ee > ul {\n",
       "  padding-left: 0 !important;\n",
       "}\n",
       "\n",
       ".ee-open,\n",
       ".ee-shut {\n",
       "  color: var(--font-color-secondary);\n",
       "  cursor: pointer;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".ee-open:hover,\n",
       ".ee-shut:hover {\n",
       "  color: var(--font-color-primary);\n",
       "}\n",
       "\n",
       ".ee-k {\n",
       "  color: var(--font-color-accent);\n",
       "  margin-right: 6px;\n",
       "}\n",
       "\n",
       ".ee-v {\n",
       "  color: var(--font-color-primary);\n",
       "}\n",
       "\n",
       ".ee-toggle {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".ee-shut + ul {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".ee-open + ul {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".ee-shut::before {\n",
       "  display: inline-block;\n",
       "  content: \"▼\";\n",
       "  margin-right: 6px;\n",
       "  transform: rotate(-90deg);\n",
       "  transition: transform 0.2s;\n",
       "}\n",
       "\n",
       ".ee-open::before {\n",
       "  transform: rotate(0deg);\n",
       "  display: inline-block;\n",
       "  content: \"▼\";\n",
       "  margin-right: 6px;\n",
       "  transition: transform 0.2s;\n",
       "}\n",
       "</style><div class='ee'><ul><li><span class='ee-v'>1</span></li></ul></div><script>function toggleHeader() {\n",
       "    const parent = this.parentElement;\n",
       "    parent.className = parent.className === \"ee-open\" ? \"ee-shut\" : \"ee-open\";\n",
       "}\n",
       "\n",
       "for (let c of document.getElementsByClassName(\"ee-toggle\")) {\n",
       "    c.onclick = toggleHeader;\n",
       "}</script></div>"
      ],
      "text/plain": [
       "<ee.ee_number.Number at 0x25778745210>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainAccuracy = trained.confusionMatrix()\n",
    "trainAccuracy.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a confusion matrix and overall accuracy for the validation sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "validationSample = validationSample.classify(trained)\n",
    "validationAccuracy = validationSample.errorMatrix(label, 'classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify the image with the same bands used for training.\n",
    "result = image.select(bands).classify(trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the results on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8bafbc93ce2401f819735d458b1fcc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=22033.0, center=[51.37, 4.999999999999999], controls=(WidgetControl(options=['position', 'transpare…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map.addLayer(result.randomVisualizer(), {}, 'classified')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To render a categorical map, we can set two image properties: `landcover_class_values` and `landcover_class_palette`. We can use the same style as the CLC so that it is easy to compare the two maps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_values = CLC.get('landcover_class_values').getInfo()\n",
    "class_palette = CLC.get('landcover_class_palette').getInfo()\n",
    "\n",
    "landcover = result.set('classification_class_values', class_values)\n",
    "landcover = landcover.set('classification_class_palette', class_palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E6004D',\n",
       " 'FF0000',\n",
       " 'CC4DF2',\n",
       " 'CC0000',\n",
       " 'E6CCCC',\n",
       " 'E6CCE6',\n",
       " 'A600CC',\n",
       " 'A64DCC',\n",
       " 'FF4DFF',\n",
       " 'FFA6FF',\n",
       " 'FFE6FF',\n",
       " 'FFFFA8',\n",
       " 'FFFF00',\n",
       " 'E6E600',\n",
       " 'E68000',\n",
       " 'F2A64D',\n",
       " 'E6A600',\n",
       " 'E6E64D',\n",
       " 'FFE6A6',\n",
       " 'FFE64D',\n",
       " 'E6CC4D',\n",
       " 'F2CCA6',\n",
       " '80FF00',\n",
       " '00A600',\n",
       " '4DFF00',\n",
       " 'CCF24D',\n",
       " 'A6FF80',\n",
       " 'A6E64D',\n",
       " 'A6F200',\n",
       " 'E6E6E6',\n",
       " 'CCCCCC',\n",
       " 'CCFFCC',\n",
       " '000000',\n",
       " 'A6E6CC',\n",
       " 'A6A6FF',\n",
       " '4D4DFF',\n",
       " 'CCCCFF',\n",
       " 'E6E6FF',\n",
       " 'A6A6E6',\n",
       " '00CCF2',\n",
       " '80F2E6',\n",
       " '00FFA6',\n",
       " 'A6FFE6',\n",
       " 'E6F2FF']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_palette"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot the results again but use the Corine Land Cover legend and colorscheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8bafbc93ce2401f819735d458b1fcc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=22033.0, center=[51.37, 4.999999999999999], controls=(WidgetControl(options=['position', 'transpare…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Map.addLayer(landcover, {}, 'Land cover')\n",
    "Map.add_legend(builtin_legend='COPERNICUS/CORINE/V20/100m')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 6. Classify the Landsat-8 using ESA WorldCover\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the Corine Land Cover data provides us with some promising results, it would be interesting to see if we can do something similar using a different data source. To do so, we are going to make use of the ESA WorldCover data.\n",
    "\n",
    "Let's start again with exploring the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8bafbc93ce2401f819735d458b1fcc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=5547.0, center=[52.86912972768522, 7.811279296875001], controls=(WidgetControl(options=['position',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ESA = ee.Image('ESA/WorldCover/v100/2020').clip(image.geometry())\n",
    "Map.addLayer(ESA, {}, 'ESA')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we generate the training set again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "classValues = [10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 100]\n",
    "remapValues = ee.List.sequence(0, 10)\n",
    "label = 'lc'\n",
    "lc = ESA.remap(classValues, remapValues).rename(label).toByte()\n",
    "\n",
    "sample = image.addBands(lc).stratifiedSample(\n",
    "    **{\n",
    "  'numPoints': 5000,\n",
    "  'classBand': label,\n",
    "  'region': image.geometry(),\n",
    "  'scale': 100,\n",
    "  'geometries': True\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again, we split the data into training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.randomColumn();\n",
    "trainingSample = sample.filter('random <= 0.8');\n",
    "validationSample = sample.filter('random > 0.8');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedClassifier = ee.Classifier.smileCart().train(\n",
    "    **{\n",
    "  'features': trainingSample,\n",
    "  'classProperty': label,\n",
    "  'inputProperties': image.bandNames()\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resulting in our newly classified map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgClassified = image.classify(trainedClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's visualize this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935f07795d9b4af5b535d99c830bbc51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=21864.0, center=[51.944264879028765, 5.369567871093751], controls=(WidgetControl(options=['position…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classVis = {\n",
    "  'min': 0,\n",
    "  'max': 10,\n",
    "  'palette': ['006400' ,'ffbb22', 'ffff4c', 'f096ff', 'fa0000', 'b4b4b4',\n",
    "            'f0f0f0', '0064c8', '0096a0', '00cf75', 'fae6a0']\n",
    "};\n",
    "\n",
    "#Map.addLayer(lc, classVis, 'lc');\n",
    "Map.addLayer(imgClassified, classVis, 'Classified');\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze and assess your Landsat-8 land cover map\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have two land cover maps generated for most part of the Netherlands, let's analyze and judge their quality.\n",
    "\n",
    "To do so, you can either zoom in on the same area you used last week to learn OpenStreetMap, or specify a different area when it is outside the bounds of our land cover map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_name = \"Steenwijk, The Netherlands\"\n",
    "area = ox.geocode_to_gdf(place_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_region = ee.Geometry.Rectangle([area.bounds.minx.values[0], \n",
    "                       area.bounds.miny.values[0],\n",
    "                       area.bounds.maxx.values[0],\n",
    "                       area.bounds.maxy.values[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating URL ...\n",
      "Downloading data from https://earthengine.googleapis.com/v1alpha/projects/earthengine-legacy/thumbnails/61125d244fa9848000fe816f56b1c0c7-9ae980350a89b2a0008f681a7dd90a12:getPixels\n",
      "Please wait ...\n",
      "Data downloaded to C:\\projects\\BigData_AED\\week5\\test.tif\n"
     ]
    }
   ],
   "source": [
    "geemap.ee_export_image(\n",
    "    imgClassified, filename='test.tif', scale=100, file_per_band=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "f323064ae63d54ed8d769390a968e914fbf7abacffc63e116cd2e04a08ed2d24"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
