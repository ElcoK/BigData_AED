{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCDarmwZ0B_P",
    "tags": []
   },
   "source": [
    "# Tutorial 1: Land-cover classification\n",
    "\n",
    "In this tutorial we are going to explore the power of the **Google Earth Engine** through classifying land-use categories on satelite imagery. In particular, we will focus on supervised classification. Supervised classification refers to the process of using a training dataset with known labels to guide a mathematical classifier in the task of labeling spectral space. They key characteristic is that the training dataset guides (or “supervises”) the labeling.\n",
    "\n",
    "The `Classifier` package within the **Google Earth Engine** handles supervised classification by traditional ML algorithms running in Earth Engine. These classifiers include CART, RandomForest, NaiveBayes and SVM. The general workflow for classification is:\n",
    "\n",
    "    1. Collect training data. Assemble features which have a property that stores the known class label and properties storing numeric values for the predictors.\n",
    "    2. Instantiate a classifier. Set its parameters if necessary.\n",
    "    3. Train the classifier using the training data.\n",
    "    4. Classify an image or feature collection.\n",
    "    5. Estimate the classification error with independent validation data.\n",
    "    \n",
    "## Important before we start\n",
    "<hr>\n",
    "Make sure that you save this file before you continue, else you will lose everything. To do so, go to Bestand/File and click on Een kopie opslaan in Drive/Save a Copy on Drive!\n",
    "\n",
    "Now, rename the file into Week5_Tutorial1.ipynb. You can do so by clicking on the name in the top of this screen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhGbHqRr0B_V"
   },
   "source": [
    "## Learning Objectives\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0cuIiyw0B_V",
    "tags": []
   },
   "source": [
    "- To understand how one can extract data from the **Google Earth Engine**.\n",
    "- To know how to visualize data from the **Google Earth Engine** in Python.\n",
    "- To understand and apply a supervised classification algorithm.\n",
    "- To be able to create training data and a simple classifier.\n",
    "- To classify Landsat-8 data using various training datasets.\n",
    "- To be able to compare and judge the performance of a land-use classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Q_vJ5ZE0B_W"
   },
   "source": [
    "<h2>Tutorial Outline<span class=\"tocSkip\"></span></h2>\n",
    "<hr>\n",
    "<div class=\"toc\"><ul class=\"toc-item\">\n",
    "<li><span><a href=\"#1.-Introducing the packages\" data-toc-modified-id=\"1.-Introducing-the-packages-2\">1. Introducing the packages</a></span></li>\n",
    "<li><span><a href=\"#2.-Extracting and exploring Landsat-8 data\" data-toc-modified-id=\"2.-Extracting-exploring-landsat-3\">2. Extracting and exploring Landsat-8 data</a></span></li>\n",
    "<li><span><a href=\"#3.-Create training data using Corine Land Cover\" data-toc-modified-id=\"3.-Create-training-data-4\">3. Create training data using Corine Land Cover</a></span></li>\n",
    "<li><span><a href=\"#4.-Train the classifier using Corine Land Cover\" data-toc-modified-id=\"4.-Classifier-CLC-5\">4.-Train the classifier using Corine Land Cover</a></span></li>\n",
    "<li><span><a href=\"#5.-Classify the Landsat-8 using Corine Land Cover\" data-toc-modified-id=\"5.-Classify-CLC-6\"> 5. Classify the Landsat-8 using Corine Land Cover</a></span></li>\n",
    "<li><span><a href=\"#6.-Classify the Landsat-8 using ESA WorldCover\" data-toc-modified-id=\"6.-Classify-ESA-7\"> 6. Classify the Landsat-8 using ESA WorldCover</a></span></li>\n",
    "<li><span><a href=\"#7.-Analyze and assess your Landsat-8 land cover map\" data-toc-modified-id=\"6.-Analyze-LLC-7\"> 7. Analyze and assess your Landsat-8 land cover map</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8qSTJEg0B_X",
    "tags": []
   },
   "source": [
    "## 1. Introducing the packages\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2Ta4PUs0B_X"
   },
   "source": [
    "Within this tutorial, we are going to make use of the following packages: \n",
    "\n",
    "[**ee**](https://developers.google.com/earth-engine/guides/python_install) is a Python package to use the the Google Earth Engine.\n",
    "\n",
    "[**geemap**](https://geemap.org/) is a Python package for interactive mapping with the Google Earth Engine.\n",
    "\n",
    "*We will first need to install these packages in the cell below. Uncomment them to make sure we can pip install them*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11735,
     "status": "ok",
     "timestamp": 1675255686011,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "M1onhJMh0B_Y",
    "outputId": "3caeae50-d278-42fa-cd67-b443d59e525a"
   },
   "outputs": [],
   "source": [
    "#!pip install ee # ee is already available in google colab so no need to install it again\n",
    "!pip install geemap\n",
    "!pip install rioxarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may or may not have seen while installing, there was a warning that we need to restart our runtime. To do so, click on **Runtime** in the topbar menu and click on **Runtime opnieuw starten**/**Restart runtime**.\n",
    "\n",
    "Now we will import these packages in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2849,
     "status": "ok",
     "timestamp": 1675255702820,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "wvqt9J2P0B_Z"
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray as rio\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap,ListedColormap\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib import rcParams, cycler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7c9PTZs0B_a"
   },
   "source": [
    "## 2.Extracting and exploring the Landsat-8 data\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sehHohh50B_b"
   },
   "source": [
    "Unfortunately it is not as simple as just running the  code below. As soon as you run it, you will notice that you need to authorize ourselves to be able to use the Google Earth Engine.\n",
    "\n",
    "To do so, we will first have to register ourselves. on the website of the [Google Earth Engine](https://earthengine.google.com/). \n",
    "\n",
    "You can choose any location in Europe, but the code below will show the coordinates we have selected for the Netherlands. Feel free to change them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 821,
     "referenced_widgets": [
      "006dc05428bf468e9724f0e0fcd388bd",
      "95d94c3ab3094ddb880ef0b9a2dce01b",
      "952b82e6c713459eb6ace9f47ada219a",
      "3d9a59a8a0a44f55ab359b66edbe3f9d",
      "036d4dad1c8f4dd3bcd37d3154fdf452",
      "ba860e12989c41e8b39524f943f8fc51",
      "402c171b86c9479f9d3cf2743b9055ff",
      "cf561e18f0dc4e578e23de278524ab78",
      "5eb406428f4d4fd2903c67dd9b9ce343",
      "c3e40ca8e6924930b1367da0f89045a3",
      "f15f98b1745248c7ae46f849862d6c9d",
      "a017674caf934e5ca12b9cf9cd77f2d1",
      "c462bdeb7af24cfd86fd72ac62e04fc7",
      "edcb631dedd44674b28172fa8d16da9b",
      "146fca8030fe4bd6b740d679d52c4838",
      "c2128a11f9bb4eb894374538f1201791",
      "2a12629894de48ce857509fbc3f44854",
      "09cfd28117b746d883b843c26ac8049c",
      "5f0e409a882f4506b42b2caaa442cc33",
      "e5e131b331024a248fe58b7ed690b170",
      "13369112cc4f4a00b2e66fd71fd18efd",
      "46d8a348d25b4416a46977c3fc2f290d",
      "259e9270784d43dd972a4fa676ed8444",
      "4cbf17f1bcf2440093c3609646365ee6",
      "741b145db27c41e4a098b52276a2a0e1",
      "0da7def710c2472ab80647a297cc6223",
      "ef2ab37274534537a07a30a7d56c5ea4",
      "e93fa2d603b04a1faafb9b1c28333856",
      "61b61a156a3644c19edec2945fab21b8",
      "a0bc2372a05943c19c357d3f7198ce30",
      "fc17ea0440bb4c1cbe6d3e4b98e0d1c7",
      "a4a869ed419c43839645d2835664636c",
      "4d10f43d2f6e46ab84d70132eaff4d60",
      "11dccc576b7345d98440c9df0d96c777",
      "557d923cb8e84c06b3b56629f6684900",
      "53e0928ed0914f6491e91a215b33573d",
      "082b7daf697b4de3befccfdc1f163478"
     ]
    },
    "executionInfo": {
     "elapsed": 1822,
     "status": "ok",
     "timestamp": 1675255707897,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "wGpIK8FO0B_b",
    "outputId": "153fad6a-b184-42c4-ba0c-ae060f901902"
   },
   "outputs": [],
   "source": [
    "Map = geemap.Map(height=800,width=700,center=[52.37,4.5],zoom=7)\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Frgjg-VU0B_c"
   },
   "source": [
    "Now we have succesfully managed to see a map of the Netherlands, let's add Landsat data to the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 569,
     "status": "ok",
     "timestamp": 1675255710789,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "NioWCK5v0B_d"
   },
   "outputs": [],
   "source": [
    "point = ee.Geometry.Point([5.0, 51.37])\n",
    "# point = ee.Geometry.Point([-87.7719, 41.8799])\n",
    "\n",
    "image = (\n",
    "    ee.ImageCollection('LANDSAT/LC08/C01/T1_SR')\n",
    "    .filterBounds(point)\n",
    "    .filterDate('2020-01-01', '2020-12-31')\n",
    "    .sort('CLOUD_COVER')\n",
    "    .first()\n",
    "    .select('B[1-7]')\n",
    ")\n",
    "\n",
    "vis_params = {'min': 0, 'max': 3000, 'bands': ['B4', 'B3', 'B2']}\n",
    "\n",
    "Map.centerObject(point, 8)\n",
    "Map.addLayer(image, vis_params, \"Landsat-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKCZxS9R0B_d"
   },
   "source": [
    "It worked! As we have specified that we wanted landsat data with as little clouds as possible, let's check the data and the actual cloud cover:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1675255713107,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "O4kmjkoM0B_e",
    "outputId": "1b801d42-590f-4781-e21c-bbfb94c1df98"
   },
   "outputs": [],
   "source": [
    "ee.Date(image.get('system:time_start')).format('YYYY-MM-dd').getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1675255714335,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "fFTjGmvV0B_e",
    "outputId": "ca10a056-5993-4b76-a2f4-a4ec5e375101"
   },
   "outputs": [],
   "source": [
    "image.get('CLOUD_COVER').getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVHCpgVoi1O_"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 1:</b> Please provide the date and the cloud cover of your map. What does this cloud cover value tell you. Do you think it is good enough? Or do you maybe want to pick a different area. If so, where did you end up eventually (and with which cloud cover)?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfU9Ih5W0B_f"
   },
   "source": [
    "## 3.Create training data using Corine Land Cover\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IzJAm-n_0B_f"
   },
   "source": [
    "Training data is instrumental to supervised image classification. The training dataset is a labeled set of data that is used to inform or “train” a classifier. The trained classifier can then be applied to new data to create a classification. For example, land cover training data will contain examples of each class in the study’s legend. Based on these labels, the classifier can predict the most likely land cover class for each pixel in an image. This is an example of a categorical classification and the training labels are therefore categorical. By contrast, a continuous variable (e.g. percent tree cover) can be predicted using continuous training labels.\n",
    "\n",
    "Let us first specify the region we are interested in! There are several ways you can create a region for generating the training dataset.\n",
    "\n",
    "- Draw a shape (e.g., rectangle) on the map and the use `region = Map.user_roi`\n",
    "- Define a geometry, such as `region = ee.Geometry.Rectangle([-122.6003, 37.4831, -121.8036, 37.8288])`\n",
    "- Create a buffer zone around a point, such as `region = ee.Geometry.Point([-122.4439, 37.7538]).buffer(10000)`\n",
    "- If you don't define a region, it will use the image footprint by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1675255718783,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "lOTsj73S0B_f"
   },
   "outputs": [],
   "source": [
    "region = ee.Geometry.Point([4.5, 52.37]).buffer(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGt7peIO0B_g"
   },
   "source": [
    "Now let's explore the Corine Land Cover data.\n",
    "\n",
    "As you will see in the cell below, we use the path where the data is located within the **Google Earth Engine** and specify that we want to see the landcover. \n",
    "\n",
    "Within that same line, we also use the `.clip()` function in which we define that we specifically only want to see the same area as the Landsat-8 image we already selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 208,
     "status": "ok",
     "timestamp": 1675255720845,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "hH0QFPo30B_g"
   },
   "outputs": [],
   "source": [
    "CLC = ee.Image('COPERNICUS/CORINE/V20/100m/2012').select('landcover').clip(image.geometry())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-mSLVjz0B_g"
   },
   "source": [
    "And let's view it on a map again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 821,
     "referenced_widgets": [
      "006dc05428bf468e9724f0e0fcd388bd",
      "95d94c3ab3094ddb880ef0b9a2dce01b",
      "952b82e6c713459eb6ace9f47ada219a",
      "3d9a59a8a0a44f55ab359b66edbe3f9d",
      "036d4dad1c8f4dd3bcd37d3154fdf452",
      "ba860e12989c41e8b39524f943f8fc51",
      "402c171b86c9479f9d3cf2743b9055ff",
      "cf561e18f0dc4e578e23de278524ab78",
      "5eb406428f4d4fd2903c67dd9b9ce343",
      "c3e40ca8e6924930b1367da0f89045a3",
      "f15f98b1745248c7ae46f849862d6c9d",
      "a017674caf934e5ca12b9cf9cd77f2d1",
      "c462bdeb7af24cfd86fd72ac62e04fc7",
      "0da7def710c2472ab80647a297cc6223",
      "ef2ab37274534537a07a30a7d56c5ea4",
      "edcb631dedd44674b28172fa8d16da9b",
      "c2128a11f9bb4eb894374538f1201791",
      "2a12629894de48ce857509fbc3f44854",
      "09cfd28117b746d883b843c26ac8049c",
      "5f0e409a882f4506b42b2caaa442cc33",
      "e5e131b331024a248fe58b7ed690b170",
      "13369112cc4f4a00b2e66fd71fd18efd",
      "46d8a348d25b4416a46977c3fc2f290d",
      "259e9270784d43dd972a4fa676ed8444",
      "4cbf17f1bcf2440093c3609646365ee6",
      "741b145db27c41e4a098b52276a2a0e1",
      "e93fa2d603b04a1faafb9b1c28333856",
      "61b61a156a3644c19edec2945fab21b8",
      "a0bc2372a05943c19c357d3f7198ce30",
      "fc17ea0440bb4c1cbe6d3e4b98e0d1c7",
      "a4a869ed419c43839645d2835664636c",
      "4d10f43d2f6e46ab84d70132eaff4d60",
      "11dccc576b7345d98440c9df0d96c777",
      "557d923cb8e84c06b3b56629f6684900",
      "53e0928ed0914f6491e91a215b33573d",
      "082b7daf697b4de3befccfdc1f163478"
     ]
    },
    "executionInfo": {
     "elapsed": 751,
     "status": "ok",
     "timestamp": 1675255723365,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "_QfHCJwW0B_h",
    "outputId": "4c695b9b-2ab9-4fca-aa1f-376b9c3f6e3e"
   },
   "outputs": [],
   "source": [
    "Map.addLayer(CLC, {}, 'CLC')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLhHhXqK0B_h"
   },
   "source": [
    "Now we are going to make the training dataset.\n",
    "\n",
    "In the `sample()` function, we have to specify multiple arguments:\n",
    "\n",
    "- Through the `region`argument we specify the geographic boundary of our training dataset.\n",
    "- Through the `scale` argument we specify the size of the points for our sample (30 would indicate 30m).\n",
    "- Through the `numPixels` argument we specify how many pixels we want to extract.\n",
    "- Through the `seed` argument we specify which random selection order we want. Through using a seed, you can always reproduce your results.\n",
    "- Through the `geometries` argument we specify whether we want to extract the geometries as well. This should always be set to True.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1675255725378,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "P0C5_sCX0B_h"
   },
   "outputs": [],
   "source": [
    "points = CLC.sample(\n",
    "    **{\n",
    "        'region': image.geometry(),\n",
    "        'scale': 100,\n",
    "        'numPixels': 5000,\n",
    "        'seed': 0,\n",
    "        'geometries': True,  # Set this to False to ignore geometries\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BI1EbbpgjYs5"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 2:</b> Describe the `.sample()` function in your own words. Which values have you chosen? And why?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DdvxczSf0B_h"
   },
   "source": [
    "Let's check how many points we got for our sample set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 559,
     "status": "ok",
     "timestamp": 1675255729643,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "ttf-3K0T0B_i",
    "outputId": "94f9ae69-250d-4d15-a3d1-bd1400fdfcfa"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(points.size().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiV3u8I50B_i"
   },
   "source": [
    "And what is the information within each of the points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 332,
     "status": "ok",
     "timestamp": 1675255731328,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "mORPLblO0B_i",
    "outputId": "81c0b9ea-64f9-40d1-e971-ec0e0aaa5cef",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(points.first().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sv7ywcDg0B_i"
   },
   "source": [
    "## 4.-Train the classifier using Corine Land Cover\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0ox2M7J0B_i"
   },
   "source": [
    "Now that we have created the points, we need to sample the Landsat-8 imagery using `.sampleRegions()`. This function will extract the reflectance in the designated bands for each of the points you have created. \n",
    "\n",
    "We will use reflectance from the optical, NIR, and SWIR bands (B2 - B7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 213,
     "status": "ok",
     "timestamp": 1675255734314,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "2IS74IjT0B_i"
   },
   "outputs": [],
   "source": [
    "# Use these bands for prediction.\n",
    "bands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7']\n",
    "\n",
    "# This property of the table stores the land cover labels.\n",
    "label = 'landcover'\n",
    "\n",
    "# Overlay the points on the imagery to get training.\n",
    "training = image.select(bands).sampleRegions(\n",
    "    **{'collection': points, 'properties': [label], 'scale': 100}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-jpbuNBc0B_j"
   },
   "source": [
    "A very important part of training a machine learning algorithm is that you ensure that there is some part of your training data left to validate your results. Here we split approximately  80% of the features into a training set and 20% into a validation set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 207,
     "status": "ok",
     "timestamp": 1675255735649,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "ygy3v8Vl0B_j"
   },
   "outputs": [],
   "source": [
    "sample = points.randomColumn();\n",
    "trainingSample = sample.filter('random <= 0.8');\n",
    "validationSample = sample.filter('random > 0.8');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UdkbPQd10B_j"
   },
   "source": [
    "And finally we extract the pixels from the LandSat-8 imagery a well to finalize our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1675255737244,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "O1pPDUhm0B_j"
   },
   "outputs": [],
   "source": [
    "# Overlay the points on the imagery to get training.\n",
    "training = image.select(bands).sampleRegions(\n",
    "    **{'collection': trainingSample, 'properties': [label], 'scale': 100}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1675255738102,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "DK2Pn7VF0B_j"
   },
   "outputs": [],
   "source": [
    "# Overlay the points on the imagery to get training.\n",
    "validation = image.select(bands).sampleRegions(\n",
    "    **{'collection': validationSample, 'properties': [label], 'scale': 100}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 3:</b> Describe in your own words why we want to split our data into training data and test data. Why is this important for the evaluation of our results?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JB9ZstM10B_k",
    "tags": []
   },
   "source": [
    "## 5. Classify and visualise the Landsat-8 using Corine Land Cover\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qB4em_8m0B_k"
   },
   "source": [
    "We are going to try various algorithms to see how they perform when we want to classify our LandSat image into land-use categories.\n",
    "\n",
    "To assess the accuracy of a classifier, we use a `ConfusionMatrix`. The `sample()` method generated two random samples from the input data: one for training and one for validation. The training sample is used to train the classifier. You can get resubstitution accuracy on the training data from `classifier.confusionMatrix()`. To get validation accuracy, we classify the validation data. This adds a `classification` property to the validation `FeatureCollection`. We will call `errorMatrix()` on the classified `FeatureCollection` to get a confusion matrix representing validation (expected) accuracy. Don't worry if things are bit unclear, we will do this step-by-step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpBDrhs60B_k"
   },
   "source": [
    "### Random Forests\n",
    "---\n",
    "Let's first use Random Forests to classify our satellite image. The inputs are specified in the [documentation](https://developers.google.com/earth-engine/apidocs/ee-classifier-smilerandomforest) of the Google Earth Engine. As you can see from the documentation, the most important input is to specify the amount of trees we are going to use. We will start with **1** and let's have a look how are model performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 200,
     "status": "ok",
     "timestamp": 1675255742180,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "OC8gLHPo0B_k"
   },
   "outputs": [],
   "source": [
    "trained_RF = ee.Classifier.smileRandomForest(1).train(training, label, bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "its-lAp50B_k"
   },
   "source": [
    "Let's first have a look at the accuracy of our training data. Accuracy represents the number of correctly classified data instances over the total number of data instances. We can calculate this by estimating a `confusion Matrix` and using the `accuracy()` function. The accuracy value ranges between 0 and 1. A value of 1 indicates that the model has fitted everything correctly.\n",
    "\n",
    "The `confusionMatrix()` computes a 2D confusion matrix for a classifier based on its training data (ie: resubstitution error). Axis 0 of the matrix correspond to the input classes (i.e., reference data), and axis 1 to the output classes (i.e., classification data). The rows and columns start at class 0 and increase sequentially up to the maximum class value.\n",
    "\n",
    "The overall Accuracy essentially tells us out of all of the reference sites what proportion were mapped correctly. The overall accuracy is usually expressed as a percent, with 100% accuracy being a perfect classification where all reference site were classified correctly. Overall accuracy is the easiest to calculate and understand but ultimately only provides the map user and producer with basic accuracy information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 920,
     "status": "ok",
     "timestamp": 1675255744186,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "EjcgN80h0B_l",
    "outputId": "42f92fae-6445-422e-a605-4024993b94fc"
   },
   "outputs": [],
   "source": [
    "trainAccuracy = trained_RF.confusionMatrix()\n",
    "trainAccuracy.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMpOi0rk0B_l"
   },
   "source": [
    "This is not very high. Let's use 10 trees and see how the results compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 489,
     "status": "ok",
     "timestamp": 1675255745440,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "qrEIkvVD0B_l",
    "outputId": "b7bd320b-b20f-4e22-fd4e-a642d619d85c"
   },
   "outputs": [],
   "source": [
    "trained_RF = ee.Classifier.smileRandomForest(10).train(training, label, bands)\n",
    "trainAccuracy = trained_RF.confusionMatrix()\n",
    "trainAccuracy.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_mCSUjeB0B_l",
    "tags": []
   },
   "source": [
    "This is more like it! What if we increase this towards 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1675255746923,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "Pw5r3-9b0B_m",
    "outputId": "8d788365-e19e-4e42-dc89-7e293917fd95"
   },
   "outputs": [],
   "source": [
    "trained_RF = ee.Classifier.smileRandomForest(100).train(training, label, bands)\n",
    "trainAccuracy = trained_RF.confusionMatrix()\n",
    "trainAccuracy.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSQe7kyF0B_m"
   },
   "source": [
    "Almost everything is now classified correctly. can we reach 100% if we would use double the amount of trees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 947,
     "status": "ok",
     "timestamp": 1675255748667,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "6PJ0d-sg0B_m",
    "outputId": "8208313b-411d-4191-ba13-0397e28f371e"
   },
   "outputs": [],
   "source": [
    "trained_RF = ee.Classifier.smileRandomForest(200).train(training, label, bands)\n",
    "trainAccuracy = trained_RF.confusionMatrix()\n",
    "trainAccuracy.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BoMaUIoc0B_n"
   },
   "source": [
    "As you noticed, it also took notable longer to get the results. And we didnt gain too much either. It would be interesting to plot these results and see how the results converge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2450,
     "status": "ok",
     "timestamp": 1675255752012,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "D-oYmE2n0B_n"
   },
   "outputs": [],
   "source": [
    "trees = [1,5,10,25,50,100,200]\n",
    "collect_accuracies = []\n",
    "for tree in trees:\n",
    "    collect_accuracies.append(ee.Classifier.smileRandomForest(tree).train(training, label, bands).confusionMatrix().accuracy().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1675255752012,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "5snBKKjH0B_n",
    "outputId": "c75fc8e0-2d2e-437c-dac0-872096ba7c53"
   },
   "outputs": [],
   "source": [
    "plt.plot(trees,collect_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKx7J2uglJj9"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 4:</b>  Upload the figure of your Random Forest Classifier progress.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 5:</b>  Please describe the figure above. What do you think would be a good value to use, and why?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDuRbAI_0B_n"
   },
   "source": [
    "The **Kappa Coefficient** is generated from a statistical test to evaluate the accuracy of a classification. **Kappa** essentially evaluates how well the classification performed as compared to just randomly assigning values, i.e. did the classification do better than random. The **Kappa Coefficient** can range from -1 to 1. A value of 0 indicated that the classification is no better than a random classification. A negative number indicates the classification is significantly worse than random. A value close to 1 indicates that the classification is significantly better than random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1168,
     "status": "ok",
     "timestamp": 1675255754998,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "mhiFrddp0B_n",
    "outputId": "eafb84b9-834a-4809-de5d-d930df4e9460"
   },
   "outputs": [],
   "source": [
    "trainAccuracy.kappa().getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FddqpU1L0B_n"
   },
   "source": [
    "Now let's have a look at some validation of our results. Through the using the 20% we reserved for validation, we can see how the model performs for the data that we did not use to train our model. `errorMatrix` computes a 2D error matrix for a collection by comparing two columns of a collection: one containing the actual values, and one containing predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 2556,
     "status": "ok",
     "timestamp": 1675255757856,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "Ijg0C-P60B_n",
    "outputId": "722297a3-8abd-49c0-9372-edd337b36f25"
   },
   "outputs": [],
   "source": [
    "validationSample = validation.classify(trained_RF)\n",
    "validationAccuracy = validationSample.errorMatrix(label, 'classification')\n",
    "validationAccuracy.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yO9NB-Hglp2g"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 6:</b> Which values did you obtain for Kappa and your validation sample. Please interpret them.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StLnH3510B_o"
   },
   "source": [
    "### CART Classifier\n",
    "---\n",
    "Next, we use a **CART** classifier to find the best method to use the spectral values to separate the labels. The classifiers known as Classification and Regression Trees (CART) partition the spectral data space successive binary splits arranged in a tree form. Graphically, classification trees identify lines that successively split the data space to separate the training points into their classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1675255757857,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "O02Zvc6c0B_o"
   },
   "outputs": [],
   "source": [
    "trained_CART = ee.Classifier.smileCart().train(training, label, bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8yr2-6C0B_o"
   },
   "source": [
    "Get a confusion matrix and overall accuracy for the training sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 223,
     "status": "ok",
     "timestamp": 1675255759740,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "DesfJjTu0B_o",
    "outputId": "2f9a5f63-ac94-4164-b876-49d5a1b9e05a"
   },
   "outputs": [],
   "source": [
    "trainAccuracy = trained_CART.confusionMatrix()\n",
    "trainAccuracy.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mvK8a2q0B_o"
   },
   "source": [
    "Get a confusion matrix and overall accuracy for the validation sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 1562,
     "status": "ok",
     "timestamp": 1675255762999,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "kknOXH-i0B_o",
    "outputId": "0cddeebd-448a-41ac-c2ad-47563340e2d2"
   },
   "outputs": [],
   "source": [
    "validationSample = validation.classify(trained_CART)\n",
    "validationAccuracy = validationSample.errorMatrix(label, 'classification')\n",
    "validationAccuracy.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWUF3S4I0B_p"
   },
   "source": [
    "### Naive Bayes\n",
    "---\n",
    "Now let's try to use the **Naive Bayes** classifier. This is classification approach that adopts the principle of class conditional independence from the Bayes Theorem. This means that the presence of one feature does not impact the presence of another in the probability of a given outcome, and each predictor has an equal effect on that result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675255763000,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "n2Ya_jcd0B_p"
   },
   "outputs": [],
   "source": [
    "trained_NaiveBayes = ee.Classifier.smileNaiveBayes().train(training, label, bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUOIAQnL0B_p"
   },
   "source": [
    "And let's get the overall accuracy of the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 609,
     "status": "ok",
     "timestamp": 1675255765049,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "zsKWKl3q0B_p",
    "outputId": "c10b2899-6b93-4d47-f490-4598918462fd"
   },
   "outputs": [],
   "source": [
    "trainAccuracy = trained_NaiveBayes.confusionMatrix()\n",
    "trainAccuracy.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "coPmQpky0B_q"
   },
   "source": [
    "And the results of our validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 1636,
     "status": "ok",
     "timestamp": 1675255767872,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "67FsgzXR0B_q",
    "outputId": "0f75177d-4c88-4077-aaf0-a943e61a3523"
   },
   "outputs": [],
   "source": [
    "validationSample = validation.classify(trained_NaiveBayes)\n",
    "validationAccuracy = validationSample.errorMatrix(label, 'classification')\n",
    "validationAccuracy.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3XX9MZw1mImP"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 7:</b> Describe the results of the CART classifier and the Naive Bayes. How did they perform and why do you think the results are different between them?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOFlaXjj0B_q",
    "tags": []
   },
   "source": [
    "### Support Vector Machine\n",
    "---\n",
    "And Finally, we will use a **Support Vector Machine**. This is a popular supervised learning model developed by Vladimir Vapnik, used for both data classification and regression. That said, it is typically leveraged for classification problems, constructing a hyperplane where the distance between two classes of data points is at its maximum. This hyperplane is known as the decision boundary, separating the classes of data points (e.g., oranges vs. apples) on either side of the plane.\n",
    "\n",
    "As you can see in the cell below, to make sure we can run the **Support Vector Machine**, we substantially reduce our training data to only 20%, instead of 80%. We do this, because running the classifier on the entire training dataset would take an extremely long time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1675255768743,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "kw8RfLdp0B_q"
   },
   "outputs": [],
   "source": [
    "trainingSample_SVM = sample.filter('random <= 0.2');\n",
    "validationSample_SVM = sample.filter('random > 0.8');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1675255769980,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "d4uhCNTY0B_q"
   },
   "outputs": [],
   "source": [
    "# Overlay the points on the imagery to get training.\n",
    "training_SVM = image.select(bands).sampleRegions(\n",
    "    **{'collection': trainingSample_SVM, 'properties': [label], 'scale': 100}\n",
    ")\n",
    "\n",
    "# Overlay the points on the imagery to get training.\n",
    "validation_SVM = image.select(bands).sampleRegions(\n",
    "    **{'collection': validationSample_SVM, 'properties': [label], 'scale': 100}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 202,
     "status": "ok",
     "timestamp": 1675255771142,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "8TBp0sI00B_r"
   },
   "outputs": [],
   "source": [
    "trained_SVM = ee.Classifier.libsvm().train(training_SVM, label, bands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TY7oY8J30B_r"
   },
   "source": [
    "Now let's have a look at the accuracy again of our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 531,
     "status": "ok",
     "timestamp": 1675255773006,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "RoudSzHZ0B_r",
    "outputId": "c99cce22-dcba-487e-a535-932e0ab6e887"
   },
   "outputs": [],
   "source": [
    "trainAccuracy = trained_SVM.confusionMatrix()\n",
    "trainAccuracy.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBE1whvp0B_r"
   },
   "source": [
    "And the results of our validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 2265,
     "status": "ok",
     "timestamp": 1675255776484,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "3htkGlHk0B_r",
    "outputId": "c6a7584b-9ba3-4125-d358-3d146a7329ef"
   },
   "outputs": [],
   "source": [
    "validationSample = validation_SVM.classify(trained_SVM)\n",
    "validationAccuracy = validationSample.errorMatrix(label, 'classification')\n",
    "validationAccuracy.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDziSfz2mc5N"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 8:</b> Describe the results of the Support Vector Machine. Are you surprised by the outcome?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBw4Qxo20B_r"
   },
   "source": [
    "### Classify and visualize output\n",
    "---\n",
    "Now let's classify the image with the same bands used for training, using the Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1675255777327,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "juCVFrd30B_r"
   },
   "outputs": [],
   "source": [
    "CLC_Classified = image.select(bands).classify(trained_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRKv-tlT0B_s"
   },
   "source": [
    "Let's look at the results on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 821,
     "referenced_widgets": [
      "006dc05428bf468e9724f0e0fcd388bd",
      "95d94c3ab3094ddb880ef0b9a2dce01b",
      "952b82e6c713459eb6ace9f47ada219a",
      "3d9a59a8a0a44f55ab359b66edbe3f9d",
      "036d4dad1c8f4dd3bcd37d3154fdf452",
      "ba860e12989c41e8b39524f943f8fc51",
      "402c171b86c9479f9d3cf2743b9055ff",
      "cf561e18f0dc4e578e23de278524ab78",
      "5eb406428f4d4fd2903c67dd9b9ce343",
      "c3e40ca8e6924930b1367da0f89045a3",
      "f15f98b1745248c7ae46f849862d6c9d",
      "a017674caf934e5ca12b9cf9cd77f2d1",
      "c462bdeb7af24cfd86fd72ac62e04fc7",
      "0da7def710c2472ab80647a297cc6223",
      "ef2ab37274534537a07a30a7d56c5ea4",
      "e93fa2d603b04a1faafb9b1c28333856",
      "edcb631dedd44674b28172fa8d16da9b",
      "c2128a11f9bb4eb894374538f1201791",
      "2a12629894de48ce857509fbc3f44854",
      "09cfd28117b746d883b843c26ac8049c",
      "5f0e409a882f4506b42b2caaa442cc33",
      "e5e131b331024a248fe58b7ed690b170",
      "13369112cc4f4a00b2e66fd71fd18efd",
      "46d8a348d25b4416a46977c3fc2f290d",
      "259e9270784d43dd972a4fa676ed8444",
      "4cbf17f1bcf2440093c3609646365ee6",
      "741b145db27c41e4a098b52276a2a0e1",
      "61b61a156a3644c19edec2945fab21b8",
      "a0bc2372a05943c19c357d3f7198ce30",
      "fc17ea0440bb4c1cbe6d3e4b98e0d1c7",
      "a4a869ed419c43839645d2835664636c",
      "4d10f43d2f6e46ab84d70132eaff4d60",
      "11dccc576b7345d98440c9df0d96c777",
      "557d923cb8e84c06b3b56629f6684900",
      "53e0928ed0914f6491e91a215b33573d",
      "082b7daf697b4de3befccfdc1f163478"
     ]
    },
    "executionInfo": {
     "elapsed": 1668,
     "status": "ok",
     "timestamp": 1675255784495,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "2O0OhpVV0B_s",
    "outputId": "eb70a56a-9881-4855-c72a-ab368a2de9fb"
   },
   "outputs": [],
   "source": [
    "Map.addLayer(CLC_Classified.randomVisualizer(), {}, 'classified')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHbF3IbH0B_s"
   },
   "source": [
    "To render a categorical map, we can set two image properties: `landcover_class_values` and `landcover_class_palette`. We can use the same style as the CLC so that it is easy to compare the two maps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1675255787083,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "qZ3FoUmk0B_s"
   },
   "outputs": [],
   "source": [
    "class_values = CLC.get('landcover_class_values').getInfo()\n",
    "class_palette = CLC.get('landcover_class_palette').getInfo()\n",
    "\n",
    "landcover = CLC_Classified.set('classification_class_values', class_values)\n",
    "landcover = landcover.set('classification_class_palette', class_palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcgvM7830B_s"
   },
   "source": [
    "Now we can plot the results again but use the Corine Land Cover legend and colorscheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 821,
     "referenced_widgets": [
      "006dc05428bf468e9724f0e0fcd388bd",
      "95d94c3ab3094ddb880ef0b9a2dce01b",
      "952b82e6c713459eb6ace9f47ada219a",
      "3d9a59a8a0a44f55ab359b66edbe3f9d",
      "036d4dad1c8f4dd3bcd37d3154fdf452",
      "ba860e12989c41e8b39524f943f8fc51",
      "402c171b86c9479f9d3cf2743b9055ff",
      "cf561e18f0dc4e578e23de278524ab78",
      "5eb406428f4d4fd2903c67dd9b9ce343",
      "a0bc2372a05943c19c357d3f7198ce30",
      "c3e40ca8e6924930b1367da0f89045a3",
      "f15f98b1745248c7ae46f849862d6c9d",
      "a017674caf934e5ca12b9cf9cd77f2d1",
      "c462bdeb7af24cfd86fd72ac62e04fc7",
      "0da7def710c2472ab80647a297cc6223",
      "ef2ab37274534537a07a30a7d56c5ea4",
      "e93fa2d603b04a1faafb9b1c28333856",
      "61b61a156a3644c19edec2945fab21b8",
      "edcb631dedd44674b28172fa8d16da9b",
      "c2128a11f9bb4eb894374538f1201791",
      "2a12629894de48ce857509fbc3f44854",
      "fc17ea0440bb4c1cbe6d3e4b98e0d1c7",
      "09cfd28117b746d883b843c26ac8049c",
      "5f0e409a882f4506b42b2caaa442cc33",
      "e5e131b331024a248fe58b7ed690b170",
      "13369112cc4f4a00b2e66fd71fd18efd",
      "a4a869ed419c43839645d2835664636c",
      "46d8a348d25b4416a46977c3fc2f290d",
      "259e9270784d43dd972a4fa676ed8444",
      "4cbf17f1bcf2440093c3609646365ee6",
      "741b145db27c41e4a098b52276a2a0e1",
      "4d10f43d2f6e46ab84d70132eaff4d60",
      "11dccc576b7345d98440c9df0d96c777",
      "557d923cb8e84c06b3b56629f6684900",
      "53e0928ed0914f6491e91a215b33573d",
      "082b7daf697b4de3befccfdc1f163478"
     ]
    },
    "executionInfo": {
     "elapsed": 1175,
     "status": "ok",
     "timestamp": 1675255789623,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "LdR9Ss3S0B_s",
    "outputId": "0cd71778-21b8-4074-e861-5a1207c29eb6"
   },
   "outputs": [],
   "source": [
    "Map.addLayer(landcover, {}, 'Land cover')\n",
    "Map.add_legend(builtin_legend='COPERNICUS/CORINE/V20/100m')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NA-L_Q9z0B_s",
    "tags": []
   },
   "source": [
    "## 6. Classify the Landsat-8 using ESA WorldCover\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3--dkQDS0B_t"
   },
   "source": [
    "While the Corine Land Cover data provides us with some promising results, it would be interesting to see if we can do something similar using a different data source. To do so, we are going to make use of the ESA WorldCover data.\n",
    "\n",
    "Let's start again with exploring the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 821,
     "referenced_widgets": [
      "006dc05428bf468e9724f0e0fcd388bd",
      "95d94c3ab3094ddb880ef0b9a2dce01b",
      "952b82e6c713459eb6ace9f47ada219a",
      "3d9a59a8a0a44f55ab359b66edbe3f9d",
      "036d4dad1c8f4dd3bcd37d3154fdf452",
      "ba860e12989c41e8b39524f943f8fc51",
      "402c171b86c9479f9d3cf2743b9055ff",
      "cf561e18f0dc4e578e23de278524ab78",
      "5eb406428f4d4fd2903c67dd9b9ce343",
      "a0bc2372a05943c19c357d3f7198ce30",
      "c3e40ca8e6924930b1367da0f89045a3",
      "f15f98b1745248c7ae46f849862d6c9d",
      "a017674caf934e5ca12b9cf9cd77f2d1",
      "c462bdeb7af24cfd86fd72ac62e04fc7",
      "0da7def710c2472ab80647a297cc6223",
      "ef2ab37274534537a07a30a7d56c5ea4",
      "e93fa2d603b04a1faafb9b1c28333856",
      "61b61a156a3644c19edec2945fab21b8",
      "53e0928ed0914f6491e91a215b33573d",
      "edcb631dedd44674b28172fa8d16da9b",
      "c2128a11f9bb4eb894374538f1201791",
      "2a12629894de48ce857509fbc3f44854",
      "fc17ea0440bb4c1cbe6d3e4b98e0d1c7",
      "09cfd28117b746d883b843c26ac8049c",
      "5f0e409a882f4506b42b2caaa442cc33",
      "e5e131b331024a248fe58b7ed690b170",
      "13369112cc4f4a00b2e66fd71fd18efd",
      "a4a869ed419c43839645d2835664636c",
      "46d8a348d25b4416a46977c3fc2f290d",
      "259e9270784d43dd972a4fa676ed8444",
      "4cbf17f1bcf2440093c3609646365ee6",
      "741b145db27c41e4a098b52276a2a0e1",
      "4d10f43d2f6e46ab84d70132eaff4d60",
      "11dccc576b7345d98440c9df0d96c777",
      "557d923cb8e84c06b3b56629f6684900",
      "082b7daf697b4de3befccfdc1f163478"
     ]
    },
    "executionInfo": {
     "elapsed": 544,
     "status": "ok",
     "timestamp": 1675255793325,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "eOtQqnxb0B_t",
    "outputId": "d720089b-faa8-4e91-bbcb-9fdcf642c21b"
   },
   "outputs": [],
   "source": [
    "ESA = ee.Image('ESA/WorldCover/v100/2020').clip(image.geometry())\n",
    "Map.addLayer(ESA, {}, 'ESA')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojprtQ2V0B_t"
   },
   "source": [
    "And now we generate the training set again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 685,
     "status": "ok",
     "timestamp": 1675255796417,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "C3OPr-x_0B_t"
   },
   "outputs": [],
   "source": [
    "classValues = [10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 100]\n",
    "remapValues = ee.List.sequence(0, 10)\n",
    "label = 'lc'\n",
    "lc = ESA.remap(classValues, remapValues).rename(label).toByte()\n",
    "\n",
    "sample = image.addBands(lc).stratifiedSample(\n",
    "    **{\n",
    "  'numPoints': 5000,\n",
    "  'classBand': label,\n",
    "  'region': image.geometry(),\n",
    "  'scale': 100,\n",
    "  'geometries': True\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o97yQzRS0B_t"
   },
   "source": [
    "And again, we split the data into training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1675255799082,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "1FIql2VI0B_t"
   },
   "outputs": [],
   "source": [
    "\n",
    "sample = sample.randomColumn();\n",
    "trainingSample = sample.filter('random <= 0.8');\n",
    "validationSample = sample.filter('random > 0.8');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nWPpXPtr0B_t"
   },
   "source": [
    "As the **CART** classifier performed best, we will re-use this one to train the algorithm through using the ESA WorldCover data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 302,
     "status": "ok",
     "timestamp": 1675255801416,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "MKhxhX7W0B_u"
   },
   "outputs": [],
   "source": [
    "trainedClassifier = ee.Classifier.smileCart().train(\n",
    "    **{\n",
    "  'features': trainingSample,\n",
    "  'classProperty': label,\n",
    "  'inputProperties': image.bandNames()\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "executionInfo": {
     "elapsed": 274,
     "status": "ok",
     "timestamp": 1675255802491,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "93o_CbXT0B_u",
    "outputId": "88639c57-3e96-4d0f-fb9c-a291c9788673"
   },
   "outputs": [],
   "source": [
    "trainAccuracy = trainedClassifier.confusionMatrix()\n",
    "trainAccuracy.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4GYp6Xee0B_u"
   },
   "source": [
    "Resulting in our newly classified map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 208,
     "status": "ok",
     "timestamp": 1675255803868,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "wMxX-9QT0B_u"
   },
   "outputs": [],
   "source": [
    "ESAWorldCover_classified = image.classify(trainedClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUUEh3MH0B_u"
   },
   "source": [
    "And let's visualize this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 821,
     "referenced_widgets": [
      "006dc05428bf468e9724f0e0fcd388bd",
      "95d94c3ab3094ddb880ef0b9a2dce01b",
      "952b82e6c713459eb6ace9f47ada219a",
      "3d9a59a8a0a44f55ab359b66edbe3f9d",
      "036d4dad1c8f4dd3bcd37d3154fdf452",
      "ba860e12989c41e8b39524f943f8fc51",
      "402c171b86c9479f9d3cf2743b9055ff",
      "cf561e18f0dc4e578e23de278524ab78",
      "5eb406428f4d4fd2903c67dd9b9ce343",
      "a0bc2372a05943c19c357d3f7198ce30",
      "c3e40ca8e6924930b1367da0f89045a3",
      "f15f98b1745248c7ae46f849862d6c9d",
      "a017674caf934e5ca12b9cf9cd77f2d1",
      "c462bdeb7af24cfd86fd72ac62e04fc7",
      "0da7def710c2472ab80647a297cc6223",
      "ef2ab37274534537a07a30a7d56c5ea4",
      "e93fa2d603b04a1faafb9b1c28333856",
      "61b61a156a3644c19edec2945fab21b8",
      "53e0928ed0914f6491e91a215b33573d",
      "082b7daf697b4de3befccfdc1f163478",
      "edcb631dedd44674b28172fa8d16da9b",
      "c2128a11f9bb4eb894374538f1201791",
      "2a12629894de48ce857509fbc3f44854",
      "fc17ea0440bb4c1cbe6d3e4b98e0d1c7",
      "09cfd28117b746d883b843c26ac8049c",
      "5f0e409a882f4506b42b2caaa442cc33",
      "e5e131b331024a248fe58b7ed690b170",
      "13369112cc4f4a00b2e66fd71fd18efd",
      "a4a869ed419c43839645d2835664636c",
      "46d8a348d25b4416a46977c3fc2f290d",
      "259e9270784d43dd972a4fa676ed8444",
      "4cbf17f1bcf2440093c3609646365ee6",
      "741b145db27c41e4a098b52276a2a0e1",
      "4d10f43d2f6e46ab84d70132eaff4d60",
      "11dccc576b7345d98440c9df0d96c777",
      "557d923cb8e84c06b3b56629f6684900"
     ]
    },
    "executionInfo": {
     "elapsed": 834,
     "status": "ok",
     "timestamp": 1675255805994,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "IQ_dprZZ0B_u",
    "outputId": "ed6fdf4d-c601-491d-996a-db4e100a9e6d"
   },
   "outputs": [],
   "source": [
    "classVis = {\n",
    "  'min': 0,\n",
    "  'max': 10,\n",
    "  'palette': ['006400' ,'ffbb22', 'ffff4c', 'f096ff', 'fa0000', 'b4b4b4',\n",
    "            'f0f0f0', '0064c8', '0096a0', '00cf75', 'fae6a0']\n",
    "};\n",
    "\n",
    "#Map.addLayer(lc, classVis, 'lc');\n",
    "Map.addLayer(ESAWorldCover_classified, classVis, 'Classified');\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHWkPEIQ0B_v"
   },
   "source": [
    "## 7. Analyze and assess your Landsat-8 land cover map\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAYl8Ru80B_v"
   },
   "source": [
    "Now we have two land cover maps generated for most part of the Netherlands, let's analyze and judge their quality.\n",
    "\n",
    "To do so, you can either zoom in on the same area you used last week to learn OpenStreetMap, or specify a different area when it is outside the bounds of our land cover map.\n",
    "\n",
    "We do so, by creating a bounding box. You can use [this website](https://boundingbox.klokantech.com/) to create a bounding box. Once you have created a bounding box, you can select the 'CSV' tab and copy paste the coordinates in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 220,
     "status": "ok",
     "timestamp": 1675255808972,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "Gqi_VPSH0B_v"
   },
   "outputs": [],
   "source": [
    "bbox = [4.248882,51.853884,4.542965,52.018829]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKuThEge0B_v"
   },
   "source": [
    "And now we can translate this into a rectangle to be used with the **Google Earth Engine**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 198,
     "status": "ok",
     "timestamp": 1675255810822,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "MuMIBg9z0B_v"
   },
   "outputs": [],
   "source": [
    "focus_region = ee.Geometry.Rectangle([bbox[0], \n",
    "                       bbox[1],\n",
    "                       bbox[2],\n",
    "                       bbox[3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNcZTd7_0B_v"
   },
   "source": [
    "### Corine Land Cover\n",
    "\n",
    "We will start with identifying how well Corine Land Cover data has been classified with our classifier. To do so, we will first download the images from the **Google Earth Engine**. To do that, we will use the `ee_export_image()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7798,
     "status": "ok",
     "timestamp": 1675255820686,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "qqWgZUGg0B_v",
    "outputId": "0d6bab8f-1a30-46cb-f98f-e61732fa4f05"
   },
   "outputs": [],
   "source": [
    "geemap.ee_export_image(\n",
    "    CLC, filename='CLC.tif', scale=100, file_per_band=False,region=focus_region\n",
    ")\n",
    "\n",
    "geemap.ee_export_image(\n",
    "    CLC_Classified, filename='CLC_Classified.tif', scale=100, file_per_band=False,region=focus_region\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EIu-PJxT0B_w"
   },
   "source": [
    "Now we can use **xarray** to open the geotiffs and prepare them for visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1675255852115,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "q2Hpvsc00B_w",
    "outputId": "23961362-a12b-44eb-98f9-4f9f70adfb61"
   },
   "outputs": [],
   "source": [
    "CLC_original = xr.open_dataset('CLC.tif', engine = 'rasterio')\n",
    "CLC_original = CLC_original.rename({'x': 'lat','y': 'lon'})\n",
    "CLC_original.rio.set_spatial_dims(x_dim=\"lat\",y_dim=\"lon\", inplace=True)\n",
    "\n",
    "CLC_classified = xr.open_dataset('CLC_Classified.tif', engine = 'rasterio')\n",
    "CLC_classified = CLC_classified.rename({'x': 'lat','y': 'lon'})\n",
    "CLC_classified.rio.set_spatial_dims(x_dim=\"lat\",y_dim=\"lon\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ai7YYvmy0B_w"
   },
   "source": [
    "Let's plot the original map (left) and the classified map (right)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "executionInfo": {
     "elapsed": 1274,
     "status": "ok",
     "timestamp": 1675255871504,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "0t0mwCj20B_w",
    "outputId": "e82e9792-657c-4f2b-bfab-44c75b6642d2"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2,figsize=(28,10))\n",
    "\n",
    "class_palette_coded = ['#'+x for x in class_palette]\n",
    "\n",
    "CLC_original[\"band_data\"].plot(ax=axes[0],levels=len(class_palette_coded),colors=class_palette_coded)\n",
    "CLC_classified[\"band_data\"].plot(ax=axes[1],levels=len(class_palette_coded),colors=class_palette_coded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFK-oJqjmx7e"
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 9:</b> Please upload the comparison figure of the original Corine Land Cover data and the classified map. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 10:</b> Describe the results of the Corine Land Cover classification. How do you think the model has performed when you zoom in on a specific area. Do you notice specific land-use classes to be worse than expected? Or better than expected? Please elaborate. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Question 11:</b> Obtain the Corine Land Cover results once more by using a different classification model. How do the results change. Have they become better, or worse? Please elaborate.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1l_3uJx80B_w",
    "tags": []
   },
   "source": [
    "### ESA World Cover\n",
    "\n",
    "Now let's do the same for our ESA World Cover. We start with downloading the results again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1652,
     "status": "ok",
     "timestamp": 1675255877973,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "mdhdogdi0B_w",
    "outputId": "7e10f9c3-f3f1-45ab-a756-dea7bcd8adbb"
   },
   "outputs": [],
   "source": [
    "geemap.ee_export_image(\n",
    "    ESA, filename='ESAWorldCover.tif', scale=100,region=focus_region, file_per_band=False\n",
    ")\n",
    "\n",
    "geemap.ee_export_image(\n",
    "    ESAWorldCover_classified, filename='ESAWorldCover_classified.tif', scale=100,region=focus_region, file_per_band=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwz5qYcP0B_x"
   },
   "source": [
    "Load the data again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1675255882516,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "4kYLuKDq0B_x"
   },
   "outputs": [],
   "source": [
    "ESA_original = xr.open_dataset('ESAWorldCover.tif', engine=\"rasterio\")\n",
    "ESA_original = ESA_original.rename({'x': 'lat','y': 'lon'})\n",
    "ESA_original.rio.set_spatial_dims(x_dim=\"lat\",y_dim=\"lon\", inplace=True)\n",
    "\n",
    "ESA_classified = xr.open_dataset('ESAWorldCover_classified.tif', engine=\"rasterio\")\n",
    "ESA_classified = ESA_classified.rename({'x': 'lat','y': 'lon'})\n",
    "ESA_classified.rio.set_spatial_dims(x_dim=\"lat\",y_dim=\"lon\", inplace=True)\n",
    "ESA_classified['band_data'] = ESA_classified['band_data']*10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qqio89gg0B_x"
   },
   "source": [
    "And now we create the `color_dict` for the ESA WorldCover:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1675255885373,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "WO-OefSB0B_x"
   },
   "outputs": [],
   "source": [
    "ESA_values = [ 10,  20,  30,  40,  50,  60,  70,  80,  90, 95, 100]\n",
    "ESA_palette = ['#006400' ,'#ffbb22', '#ffff4c', '#f096ff', '#fa0000', '#b4b4b4',\n",
    "            '#f0f0f0', '#0064c8', '#0096a0', '#00cf75', '#fae6a0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bsZpa81P0B_x"
   },
   "source": [
    "But our clipped data is looking a litle bit different. Let's have a look at the values for the original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1675255887449,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "Ko9fgYHN0B_x",
    "outputId": "d46f896f-a621-4a4e-b489-9688d57c97ea"
   },
   "outputs": [],
   "source": [
    "np.unique(ESA_original['band_data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IHD-pgPR0B_y"
   },
   "source": [
    "And our classified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1675255889548,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "AZeAvTZq0B_y",
    "outputId": "f8f00351-5700-4c28-c94e-c6d886d29a8c"
   },
   "outputs": [],
   "source": [
    "np.unique(ESA_classified['band_data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IkxMDMxq0B_y"
   },
   "source": [
    "If we look at the [Land Cover classes](https://developers.google.com/earth-engine/datasets/catalog/ESA_WorldCover_v100), we see that we may not have some of the higher values in the Netherlands. So let's create a palette with just the land cover classes we have in the Netherlands "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 287,
     "status": "ok",
     "timestamp": 1675255891660,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "DS-rA0VU0B_y"
   },
   "outputs": [],
   "source": [
    "original_palette = [ESA_palette[int(x/10)-1] for x \n",
    "                      in np.unique(ESA_original['band_data'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1675255893134,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "q0M6L1JU0B_y"
   },
   "outputs": [],
   "source": [
    "classified_palette = [ESA_palette[int(x/10)-1] for \n",
    "                      x in np.unique(ESA_classified['band_data']) if ~np.isnan(x)]+['#000000']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXLxVyxL0B_y"
   },
   "source": [
    "And plot the two maps to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "executionInfo": {
     "elapsed": 1172,
     "status": "ok",
     "timestamp": 1675255896385,
     "user": {
      "displayName": "RA Odongo",
      "userId": "17326618845752559881"
     },
     "user_tz": -60
    },
    "id": "gcccGb-w0B_y",
    "outputId": "dee0b5cb-fd4c-4b23-b38c-a7ebdf8ad8ef"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2,figsize=(28,10))\n",
    "\n",
    "ESA_original[\"band_data\"].plot(ax=axes[0],levels=len(original_palette),colors=original_palette)\n",
    "ESA_classified[\"band_data\"].plot(ax=axes[1],levels=len(classified_palette),colors=classified_palette)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/ElcoK/BigData_AED/blob/main/week5/tutorial1.ipynb",
     "timestamp": 1674849567568
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "f323064ae63d54ed8d769390a968e914fbf7abacffc63e116cd2e04a08ed2d24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
